# Images
LLAMA_CPP_IMAGE=ghcr.io/ggml-org/llama.cpp:server
OPEN_WEBUI_IMAGE=ghcr.io/open-webui/open-webui:dev
KOKORO_TTS_IMAGE=ghcr.io/remsky/kokoro-fastapi-cpu:latest

# Model config
MODEL_FILENAME=
# MODEL_DIRECTORY=
#CHAT_TEMPLATE=llama2

# LLaMA config (values are for 2022 M2 8GB MacBook Pro)
# CTX_SIZE=2048
# GPU_LAYERS=24
# BATCH_SIZE=512
# MLOCK=true

# Keys
#AUDIO_TTS_OPENAI_API_KEY=
#WEBUI_SECRET_KEY=

# Custom ports configuration
#KOKORO_TTS_PORT=
#LLAMA_PORT=
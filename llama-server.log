build: 5760 (e8215dbb) with Apple clang version 15.0.0 (clang-1500.3.9.4) for arm64-apple-darwin23.6.0
system info: n_threads = 4, n_threads_batch = 4, total_threads = 10

system_info: n_threads = 4 (n_threads_batch = 4) / 10 | Metal : EMBED_LIBRARY = 1 | BF16 = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | LLAMAFILE = 1 | ACCELERATE = 1 | REPACK = 1 | 

main: binding port with default address family
main: HTTP server is listening, hostname: 127.0.0.1, port: 10000, http threads: 9
main: loading model
srv    load_model: loading model '/Users/thomas/Coding/personal/local-llama/scripts/../models/'
llama_model_load_from_file_impl: using device Metal (Apple M4) - 10922 MiB free
gguf_init_from_file_impl: failed to read magic
llama_model_load: error loading model: llama_model_loader: failed to load model from /Users/thomas/Coding/personal/local-llama/scripts/../models/
llama_model_load_from_file_impl: failed to load model
common_init_from_params: failed to load model '/Users/thomas/Coding/personal/local-llama/scripts/../models/'
srv    load_model: failed to load model, '/Users/thomas/Coding/personal/local-llama/scripts/../models/'
srv    operator(): operator(): cleaning up before exit...
main: exiting due to model loading error
